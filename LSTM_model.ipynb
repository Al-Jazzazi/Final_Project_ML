{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Al-Jazzazi/Final_Project_ML/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNapoxgFQYrf",
        "outputId": "742c6a36-3b3b-43cd-c3fb-3db6dde1bbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/chethuhn/network-intrusion-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"chethuhn/network-intrusion-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2a2VdaCpQcqG"
      },
      "outputs": [],
      "source": [
        "all_files = [\n",
        "    \"Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
        "    \"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
        "    \"Wednesday-workingHours.pcap_ISCX.csv\",\n",
        "    \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
        "    \"Monday-WorkingHours.pcap_ISCX.csv\",\n",
        "    \"Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
        "    \"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
        "    \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3il13s66Qerm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Combine all CSV files into a single dataframe\n",
        "dataframes = []\n",
        "for file in all_files:\n",
        "    # Make sure to replace with the correct file path\n",
        "    df = pd.read_csv(os.path.join(path, file))\n",
        "    dataframes.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "14cOiKpjQioH"
      },
      "outputs": [],
      "source": [
        "# Concatenate all dataframes\n",
        "df = pd.concat(dataframes, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s-IwZlCuQl_E"
      },
      "outputs": [],
      "source": [
        "# Data cleaning: Replace infinity with NaN and drop rows with NaN values\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9DlLWmEwQo_d"
      },
      "outputs": [],
      "source": [
        "# Extract features and labels\n",
        "X = np.array(df.drop(columns=' Label'))\n",
        "y = np.array(df[' Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vYjeSlLKQqXj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a9G4dXpUQrtj"
      },
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_O0yo50tQtcy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_sections = 100\n",
        "\n",
        "x_sections = np.array_split(X_scaled, num_sections)\n",
        "y_sections = np.array_split(y, num_sections)\n",
        "\n",
        "indices = np.arange(num_sections)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Shuffle x and y sections using the same order\n",
        "x_sections = [x_sections[i] for i in indices]\n",
        "y_sections = [y_sections[i] for i in indices]\n",
        "\n",
        "x_flattened = np.vstack(x_sections)\n",
        "y_flattened = np.hstack(y_sections)\n",
        "\n",
        "split_index = int(0.8 * len(X))\n",
        "\n",
        "X_reshaped = x_flattened.reshape((x_flattened.shape[0], 1, x_flattened.shape[1]))\n",
        "Y_onehot = to_categorical(y_flattened, num_classes=15)\n",
        "# Sequential split\n",
        "X_train, X_test = X_reshaped[:split_index], X_reshaped[split_index:]\n",
        "y_train, y_test = Y_onehot[:split_index], Y_onehot[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "N0CqK5Z6pBb7",
        "outputId": "039ef632-7eaa-4285-824a-4a2d1512f9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m36,608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m495\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,183\u001b[0m (153.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,183</span> (153.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,183\u001b[0m (153.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,183</span> (153.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))  # LSTM layer\n",
        "model.add(Dense(32, activation='relu'))  # Dense hidden layer\n",
        "model.add(Dense(15, activation='softmax'))  # Output layer for 15 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7NHjiAWp6Rl"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-LgkVW-qC4q"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "HVgkeza-v5EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "udXxm-T6v8LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "OQ6lM2WZwHRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate FPR and FNR\n",
        "FP = cm.sum(axis=0) - np.diag(cm)  # False Positives\n",
        "FN = cm.sum(axis=1) - np.diag(cm)  # False Negatives\n",
        "TP = np.diag(cm)                   # True Positives\n",
        "TN = cm.sum() - (FP + FN + TP)     # True Negatives\n",
        "\n",
        "# False Positive Rate and False Negative Rate\n",
        "FPR = FP / (FP + TN)\n",
        "FNR = FN / (FN + TP)\n",
        "\n",
        "print(f\"False Positive Rates: {[round(fpr, 5) for fpr in FPR]}\")\n",
        "print(f\"False Negative Rates: {[round(fnr, 5) for fnr in FNR]}\")"
      ],
      "metadata": {
        "id": "4cgcy0-vwLS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The number of attacks predicted by the model: \", len(np.unique(y_pred)))\n",
        "print(\"The number of attacks exist in dataset: \", len(np.unique(y_test)))\n"
      ],
      "metadata": {
        "id": "Imgsu9WAwMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts = np.unique(y, return_counts=True)\n",
        "labels = np.unique(df[' Label'])\n",
        "for label, element, count in zip( labels , unique_elements, counts):\n",
        "      print(f\"Element {label}: {count} occurrences\")"
      ],
      "metadata": {
        "id": "ifgiycZFwOnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does the Intrusion Detection System perform?**\n",
        "without regard to wether it classified the attack correctly, How does the model perform in distinguishing attacks from benign traffic?"
      ],
      "metadata": {
        "id": "Km_0Kq-SwUUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "I_pred = y_pred == 0\n",
        "I_test = y_test == 0\n"
      ],
      "metadata": {
        "id": "UXUA5ESowQqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, f1_score\n",
        "\n",
        "# Calculate precision, accuracy, and F1-score\n",
        "precision = precision_score(I_test, I_pred)\n",
        "accuracy = accuracy_score(I_test, I_pred)\n",
        "f1 = f1_score(I_test, I_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "WLKLo5WGwSIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "false_positives = np.sum((I_pred == True) & (I_test == False))/np.sum(I_pred == True)\n",
        "false_negatives = np.sum((I_pred == False) & (I_test == True))/np.sum(I_pred == False)\n",
        "print(\"false positives percent amongst all positives (ie predicting BENIGN when actual is attack) \", false_positives)\n",
        "print(\"false negatives percent amongst all negatives (ie predicting Attack when actual is benign) \", false_negatives)\n"
      ],
      "metadata": {
        "id": "vM2WseX6wWmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jXNQ8cYnwZhp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZtDDQWmDU9vaycdY8I/vr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}